diff --git a/configure b/configure
index 08a54a7..c1a83b1 100755
--- a/configure
+++ b/configure
@@ -3494,6 +3494,10 @@ nlmeans_opencl_filter_deps="opencl"
 nnedi_filter_deps="gpl"
 ocr_filter_deps="libtesseract"
 ocv_filter_deps="libopencv"
+perceptual_filter_deps="libopencv"
+perceptual_filter_extralibs="-lstdc++ -lopencv_img_hash"
+img_hash_filter_deps="libopencv"
+img_hash_filter_extralibs="-lstdc++ -lopencv_img_hash"
 openclsrc_filter_deps="opencl"
 overlay_opencl_filter_deps="opencl"
 overlay_qsv_filter_deps="libmfx"
diff --git a/libavcodec/libx264.c b/libavcodec/libx264.c
index 86e3530..a18baed 100644
--- a/libavcodec/libx264.c
+++ b/libavcodec/libx264.c
@@ -195,24 +195,73 @@ static void reconfig_encoder(AVCodecContext *ctx, const AVFrame *frame)
         x264_encoder_reconfig(x4->enc, &x4->params);
     }
 
-    if (x4->params.rc.i_vbv_buffer_size != ctx->rc_buffer_size / 1000 ||
-        x4->params.rc.i_vbv_max_bitrate != ctx->rc_max_rate    / 1000) {
-        x4->params.rc.i_vbv_buffer_size = ctx->rc_buffer_size / 1000;
-        x4->params.rc.i_vbv_max_bitrate = ctx->rc_max_rate    / 1000;
-        x264_encoder_reconfig(x4->enc, &x4->params);
+    if (frame->perceptual_score == -1) {
+        if (x4->params.rc.i_vbv_buffer_size != ctx->rc_buffer_size / 1000 ||
+            x4->params.rc.i_vbv_max_bitrate != ctx->rc_max_rate    / 1000) {
+            x4->params.rc.i_vbv_buffer_size = ctx->rc_buffer_size / 1000;
+            x4->params.rc.i_vbv_max_bitrate = ctx->rc_max_rate    / 1000;
+            x264_encoder_reconfig(x4->enc, &x4->params);
+        }
     }
 
     if (x4->params.rc.i_rc_method == X264_RC_ABR &&
-        x4->params.rc.i_bitrate != ctx->bit_rate / 1000) {
-        x4->params.rc.i_bitrate = ctx->bit_rate / 1000;
-        x264_encoder_reconfig(x4->enc, &x4->params);
+        (frame->perceptual_score > -1 ||
+         x4->params.rc.i_bitrate != ctx->bit_rate / 1000)) {
+        if (frame->perceptual_score > -1) {
+            int bitrate = 0;
+            /* set ABR bitrate value from perceptual score */
+            /* decrease compression by raising the avg bitrate up to N times */
+            bitrate = (ctx->bit_rate / 1000) + ((frame->perceptual_score * frame->perceptual_score_factor) * (ctx->bit_rate / 1000.0));
+            x4->params.rc.i_bitrate = bitrate;
+            x4->params.rc.i_vbv_max_bitrate = bitrate * 1.5;
+            x4->params.rc.i_vbv_buffer_size = bitrate * 1.5 * 1.5;
+            av_log(ctx, AV_LOG_DEBUG,
+               "Perceptual: bitrate %d maxbitrate %d from %"PRIu64"\n", 
+               x4->params.rc.i_bitrate, 
+               x4->params.rc.i_vbv_max_bitrate,
+               ctx->bit_rate / 1000);
+
+            /* tag this frame with this specific config */
+            x4->pic.param = &x4->params;
+            x264_encoder_reconfig(x4->enc, &x4->params);
+        } else {
+            x4->params.rc.i_bitrate = ctx->bit_rate / 1000;
+            x264_encoder_reconfig(x4->enc, &x4->params);
+        }
     }
 
     if (x4->crf >= 0 &&
         x4->params.rc.i_rc_method == X264_RC_CRF &&
-        x4->params.rc.f_rf_constant != x4->crf) {
-        x4->params.rc.f_rf_constant = x4->crf;
-        x264_encoder_reconfig(x4->enc, &x4->params);
+        (frame->perceptual_score > -1 ||
+         x4->params.rc.f_rf_constant != x4->crf)) {
+        if (frame->perceptual_score > -1) {
+            float crf_value = 0.0;
+            if (ctx->rc_max_rate) {
+                int bitrate = 0;
+                /* set crf value from perceptual score */
+                /* decrease compression by lowering the score by up to N CRF points */
+                crf_value = x4->crf - ((frame->perceptual_score * 100.0) / (frame->perceptual_score_factor * 2));
+                x4->params.rc.f_rf_constant = crf_value;
+
+                /* set ABR bitrate value from perceptual score */
+                /* decrease compression by raising the avg bitrate up to N times */
+                bitrate = (ctx->rc_max_rate / 1000) + ((frame->perceptual_score * frame->perceptual_score_factor) * (ctx->rc_max_rate / 1000.0));
+                x4->params.rc.i_vbv_max_bitrate = bitrate;
+                x4->params.rc.i_vbv_buffer_size = bitrate * 1.5 * 1.5;
+            }
+            av_log(ctx, AV_LOG_DEBUG,
+               "Perceptual: crf: %0.2f bitrate %d maxbitrate %d from %"PRIu64"\n", 
+               x4->params.rc.f_rf_constant,
+               x4->params.rc.i_bitrate, 
+               x4->params.rc.i_vbv_max_bitrate,
+               ctx->rc_max_rate / 1000);
+
+            /* tag this frame with this specific config */
+            x4->pic.param = &x4->params;
+        } else {
+            x4->params.rc.f_rf_constant = x4->crf;
+            x264_encoder_reconfig(x4->enc, &x4->params);
+        }
     }
 
     if (x4->params.rc.i_rc_method == X264_RC_CQP &&
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index 3ef4191..c59d036 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -309,6 +309,8 @@ OBJS-$(CONFIG_NORMALIZE_FILTER)              += vf_normalize.o
 OBJS-$(CONFIG_NULL_FILTER)                   += vf_null.o
 OBJS-$(CONFIG_OCR_FILTER)                    += vf_ocr.o
 OBJS-$(CONFIG_OCV_FILTER)                    += vf_libopencv.o
+OBJS-$(CONFIG_PERCEPTUAL_FILTER)             += vf_perceptual.o img_hash.o
+OBJS-$(CONFIG_IMG_HASH_FILTER)               += vf_img_hash.o img_hash.o
 OBJS-$(CONFIG_OSCILLOSCOPE_FILTER)           += vf_datascope.o
 OBJS-$(CONFIG_OVERLAY_FILTER)                += vf_overlay.o framesync.o
 OBJS-$(CONFIG_OVERLAY_OPENCL_FILTER)         += vf_overlay_opencl.o opencl.o \
@@ -492,6 +494,7 @@ OBJS-$(CONFIG_SHARED)                        += log2_tab.o
 SKIPHEADERS-$(CONFIG_QSVVPP)                 += qsvvpp.h
 SKIPHEADERS-$(CONFIG_OPENCL)                 += opencl.h
 SKIPHEADERS-$(CONFIG_VAAPI)                  += vaapi_vpp.h
+SKIPHEADERS-$(CONFIG_LIBOPENCV)              += img_hash.h
 
 TOOLS     = graph2dot
 TESTPROGS = drawutils filtfmts formats integral
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index b675c68..81d8c86 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -294,6 +294,8 @@ extern AVFilter ff_vf_normalize;
 extern AVFilter ff_vf_null;
 extern AVFilter ff_vf_ocr;
 extern AVFilter ff_vf_ocv;
+extern AVFilter ff_vf_perceptual;
+extern AVFilter ff_vf_img_hash;
 extern AVFilter ff_vf_oscilloscope;
 extern AVFilter ff_vf_overlay;
 extern AVFilter ff_vf_overlay_opencl;
diff --git a/libavfilter/img_hash.cpp b/libavfilter/img_hash.cpp
new file mode 100644
index 0000000..e6bf32f
--- /dev/null
+++ b/libavfilter/img_hash.cpp
@@ -0,0 +1,86 @@
+// Christopher Kennedy 2019
+// License: Apache 2.0
+//
+// Originally inspired by the information from:
+// https://qtandopencv.blogspot.com/2016/06/introduction-to-image-hash-module-of.html
+//
+#include <opencv2/core.hpp>
+#include <opencv2/core/ocl.hpp>
+#include <opencv2/highgui.hpp>
+#include <opencv2/img_hash.hpp>
+#include <opencv2/imgproc.hpp>
+
+#include <iostream>
+
+#include "img_hash.h"
+#include "libavutil/pixdesc.h"
+extern "C" {
+#include "avfilter.h"
+}
+
+using namespace cv;
+using namespace cv::img_hash;
+using namespace std;
+
+// From the libopencv AVFilter
+static void fill_iplimage_from_frame(IplImage *img, const AVFrame *frame, enum AVPixelFormat pixfmt)
+{
+    IplImage *tmpimg;
+    int depth, channels_nb;
+
+    if      (pixfmt == AV_PIX_FMT_GRAY8) { depth = IPL_DEPTH_8U;  channels_nb = 1; }
+    else if (pixfmt == AV_PIX_FMT_BGRA)  { depth = IPL_DEPTH_8U;  channels_nb = 4; }
+    else if (pixfmt == AV_PIX_FMT_BGR24) { depth = IPL_DEPTH_8U;  channels_nb = 3; }
+    else if (pixfmt == AV_PIX_FMT_YUV420P) { depth = IPL_DEPTH_8U;  channels_nb = 3; }
+    else return;
+
+    tmpimg = cvCreateImageHeader((CvSize){frame->width, frame->height}, depth, channels_nb);
+    *img = *tmpimg;
+    img->imageData = img->imageDataOrigin = (char *) frame->data[0];
+    img->dataOrder = IPL_DATA_ORDER_PIXEL;
+    img->origin    = IPL_ORIGIN_TL;
+    img->widthStep = frame->linesize[0];
+}
+
+// Get the score of two Video Frames by comparing the perceptual hashes and deriving a hamming distance
+// showing how similar they are or different. lower the score is better for most algorithms
+extern "C" double getScore(const AVFrame *frame1, const AVFrame *frame2, enum AVPixelFormat pixfmt, int hash_type) {
+    cv::Ptr<cv::img_hash::ImgHashBase> algo;
+    IplImage ipl1, ipl2;
+    cv::Mat h1;
+    cv::Mat h2;
+    cv::Mat m1;
+    cv::Mat m2;
+
+    // Take FFmpeg video frame and convert into an IplImage for OpenCV
+    fill_iplimage_from_frame(&ipl1, frame1, pixfmt);
+    fill_iplimage_from_frame(&ipl2, frame2, pixfmt);
+    // Convert an IplImage to an Mat Image for OpenCV (newer format)
+    m1 = cv::cvarrToMat(&ipl1);
+    m2 = cv::cvarrToMat(&ipl2);
+
+    // substantiate the hash type algorithm
+    if (hash_type == COLORMOMENT) {
+        algo = cv::img_hash::ColorMomentHash::create();
+    } else if (hash_type == AVERAGE) {
+        algo = cv::img_hash::AverageHash::create();
+    } else if (hash_type == BLOCKMEAN1) {
+        //BlockMeanHash support mode 0 and mode 1, they associate to 
+        //    //mode 1 and mode 2 of PHash library
+        algo = cv::img_hash::BlockMeanHash::create(0);
+    } else if (hash_type == BLOCKMEAN2) {
+        algo = cv::img_hash::BlockMeanHash::create(1);
+    } else if (hash_type == MARRHILDRETH) {
+        algo = cv::img_hash::MarrHildrethHash::create();
+    } else if (hash_type == RADIALVARIANCE) {
+        algo = cv::img_hash::RadialVarianceHash::create();
+    } else { // Default to PHash
+        algo = cv::img_hash::PHash::create();
+    }
+    // Compute the hash
+    algo->compute(m1, h1);
+    algo->compute(m2, h2);
+    // Compare the hashes and return the hamming distance
+    return algo->compare(h1, h2);
+}
+
diff --git a/libavfilter/img_hash.h b/libavfilter/img_hash.h
new file mode 100644
index 0000000..a17b0cb
--- /dev/null
+++ b/libavfilter/img_hash.h
@@ -0,0 +1,31 @@
+// Christopher Kennedy 2019
+// License: Apache 2.0
+//
+// Tutorial and code from
+// https://qtandopencv.blogspot.com/2016/06/introduction-to-image-hash-module-of.html
+//
+#ifndef AVFILTER_IMG_HASH_H
+#define AVFILTER_IMG_HASH_H
+
+#include "avfilter.h"
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+#define PHASH 0
+#define COLORMOMENT 1
+#define AVERAGE 2
+#define MARRHILDRETH 2
+#define RADIALVARIANCE 3
+#define BLOCKMEAN1 4
+#define BLOCKMEAN2 5
+
+double getScore(const AVFrame *frame1, const AVFrame *frame2, enum AVPixelFormat pixfmt, int hash_type);
+#ifdef __cplusplus
+}
+#endif
+
+
+#endif
diff --git a/libavfilter/vf_img_hash.c b/libavfilter/vf_img_hash.c
new file mode 100644
index 0000000..23bb374
--- /dev/null
+++ b/libavfilter/vf_img_hash.c
@@ -0,0 +1,453 @@
+/*
+ * Copyright (c) 2019 Christopher Kennedy
+ *
+ * PHQM Perceptual Hash Quality Metric
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * PHQM: Caculate the Image Hash Hamming Difference between two input videos.
+ */
+
+#include "libavutil/avstring.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "avfilter.h"
+#include "drawutils.h"
+#include "formats.h"
+#include "framesync.h"
+#include "internal.h"
+#include "psnr.h"
+#include "video.h"
+
+#include "img_hash.h"
+
+typedef struct ImgHashContext {
+    const AVClass *class;
+    FFFrameSync fs;
+    double hd, mse, min_mse, max_mse, mse_comp[4];
+    uint64_t nb_frames;
+    FILE *stats_file;
+    char *stats_file_str;
+    int stats_version;
+    char *hash_type;
+    int hash_type_i;
+    int stats_header_written;
+    int stats_add_max;
+    int max[4], average_max;
+    int is_rgb;
+    uint8_t rgba_map[4];
+    char comps[4];
+    int nb_components;
+    int planewidth[4];
+    int planeheight[4];
+    double planeweight[4];
+    PSNRDSPContext dsp;
+} ImgHashContext;
+
+#define OFFSET(x) offsetof(ImgHashContext, x)
+#define FLAGS AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM
+
+static const AVOption img_hash_options[] = {
+    {"stats_file", "Set file where to store per-frame difference information", OFFSET(stats_file_str), AV_OPT_TYPE_STRING, {.str=NULL}, 0, 0, FLAGS },
+    {"f",          "Set file where to store per-frame difference information", OFFSET(stats_file_str), AV_OPT_TYPE_STRING, {.str=NULL}, 0, 0, FLAGS },
+    {"stats_version", "Set the format version for the stats file.",               OFFSET(stats_version),  AV_OPT_TYPE_INT,    {.i64=1},    1, 2, FLAGS },
+    {"output_max",  "Add raw stats (max values) to the output log.",            OFFSET(stats_add_max), AV_OPT_TYPE_BOOL, {.i64=0}, 0, 1, FLAGS},
+    { "hash_type", "options: phash, colormomenthash, average", OFFSET(hash_type), AV_OPT_TYPE_STRING, {.str = "phash"}, .flags = FLAGS },
+    { NULL }
+};
+
+FRAMESYNC_DEFINE_CLASS(img_hash, ImgHashContext, fs);
+
+static inline unsigned pow_2(unsigned base)
+{
+    return base*base;
+}
+
+static inline double get_psnr(double mse, uint64_t nb_frames, int max)
+{
+    return 10.0 * log10(pow_2(max) / (mse / nb_frames));
+}
+
+static uint64_t sse_line_8bit(const uint8_t *main_line,  const uint8_t *ref_line, int outw)
+{
+    int j;
+    unsigned m2 = 0;
+
+    for (j = 0; j < outw; j++)
+        m2 += pow_2(main_line[j] - ref_line[j]);
+
+    return m2;
+}
+
+static uint64_t sse_line_16bit(const uint8_t *_main_line, const uint8_t *_ref_line, int outw)
+{
+    int j;
+    uint64_t m2 = 0;
+    const uint16_t *main_line = (const uint16_t *) _main_line;
+    const uint16_t *ref_line = (const uint16_t *) _ref_line;
+
+    for (j = 0; j < outw; j++)
+        m2 += pow_2(main_line[j] - ref_line[j]);
+
+    return m2;
+}
+
+static inline
+void compute_images_mse(ImgHashContext *s,
+                        const uint8_t *main_data[4], const int main_linesizes[4],
+                        const uint8_t *ref_data[4], const int ref_linesizes[4],
+                        int w, int h, double mse[4])
+{
+    int i, c;
+
+    for (c = 0; c < s->nb_components; c++) {
+        const int outw = s->planewidth[c];
+        const int outh = s->planeheight[c];
+        const uint8_t *main_line = main_data[c];
+        const uint8_t *ref_line = ref_data[c];
+        const int ref_linesize = ref_linesizes[c];
+        const int main_linesize = main_linesizes[c];
+        uint64_t m = 0;
+        for (i = 0; i < outh; i++) {
+            m += s->dsp.sse_line(main_line, ref_line, outw);
+            ref_line += ref_linesize;
+            main_line += main_linesize;
+        }
+        mse[c] = m / (double)(outw * outh);
+    }
+}
+
+static void set_meta(AVDictionary **metadata, const char *key, char comp, float d)
+{
+    char value[128];
+    snprintf(value, sizeof(value), "%0.2f", d);
+    if (comp) {
+        char key2[128];
+        snprintf(key2, sizeof(key2), "%s%c", key, comp);
+        av_dict_set(metadata, key2, value, 0);
+    } else {
+        av_dict_set(metadata, key, value, 0);
+    }
+}
+
+static int do_psnr(FFFrameSync *fs)
+{
+    AVFilterContext *ctx = fs->parent;
+    ImgHashContext *s = ctx->priv;
+    AVFrame *master, *ref;
+    double comp_mse[4], mse = 0, hd = 0;
+    int ret, j, c;
+    AVDictionary **metadata;
+
+    ret = ff_framesync_dualinput_get(fs, &master, &ref);
+    if (ret < 0)
+        return ret;
+    if (!ref)
+        return ff_filter_frame(ctx->outputs[0], master);
+    metadata = &master->metadata;
+
+    compute_images_mse(s, (const uint8_t **)master->data, master->linesize,
+                          (const uint8_t **)ref->data, ref->linesize,
+                          master->width, master->height, comp_mse);
+
+    for (j = 0; j < s->nb_components; j++)
+        mse += comp_mse[j] * s->planeweight[j];
+
+    s->min_mse = FFMIN(s->min_mse, mse);
+    s->max_mse = FFMAX(s->max_mse, mse);
+
+    s->mse += mse;
+    for (j = 0; j < s->nb_components; j++)
+        s->mse_comp[j] += comp_mse[j];
+    s->nb_frames++;
+
+    for (j = 0; j < s->nb_components; j++) {
+        c = s->is_rgb ? s->rgba_map[j] : j;
+        set_meta(metadata, "lavfi.psnr.mse.", s->comps[j], comp_mse[c]);
+        set_meta(metadata, "lavfi.psnr.psnr.", s->comps[j], get_psnr(comp_mse[c], 1, s->max[c]));
+    }
+    set_meta(metadata, "lavfi.psnr.mse_avg", 0, mse);
+    set_meta(metadata, "lavfi.psnr.psnr_avg", 0, get_psnr(mse, 1, s->average_max));
+
+    /* get ref / enc perceptual hashes and calc hamming distance difference value */
+    s->hd += hd = getScore(ref, master, ref->format, s->hash_type_i);
+    av_log(s, AV_LOG_DEBUG, "ImgHash: %s hamming distance %0.1lf\n", s->hash_type, hd);
+
+    if (s->stats_file) {
+        if (s->stats_version == 2 && !s->stats_header_written) {
+            fprintf(s->stats_file, "psnr_log_version:2 fields:n");
+            fprintf(s->stats_file, ",mse_avg");
+            for (j = 0; j < s->nb_components; j++) {
+                fprintf(s->stats_file, ",mse_%c", s->comps[j]);
+            }
+            fprintf(s->stats_file, ",psnr_avg");
+            for (j = 0; j < s->nb_components; j++) {
+                fprintf(s->stats_file, ",psnr_%c", s->comps[j]);
+            }
+            if (s->stats_add_max) {
+                fprintf(s->stats_file, ",max_avg");
+                for (j = 0; j < s->nb_components; j++) {
+                    fprintf(s->stats_file, ",max_%c", s->comps[j]);
+                }
+            }
+            fprintf(s->stats_file, "\n");
+            s->stats_header_written = 1;
+        }
+        fprintf(s->stats_file, "n:%"PRId64" phqm_avg:%0.2f mse_avg:%0.2f ", s->nb_frames, hd, mse);
+        for (j = 0; j < s->nb_components; j++) {
+            c = s->is_rgb ? s->rgba_map[j] : j;
+            fprintf(s->stats_file, "mse_%c:%0.2f ", s->comps[j], comp_mse[c]);
+        }
+        fprintf(s->stats_file, "psnr_avg:%0.2f ", get_psnr(mse, 1, s->average_max));
+        for (j = 0; j < s->nb_components; j++) {
+            c = s->is_rgb ? s->rgba_map[j] : j;
+            fprintf(s->stats_file, "psnr_%c:%0.2f ", s->comps[j],
+                    get_psnr(comp_mse[c], 1, s->max[c]));
+        }
+        if (s->stats_version == 2 && s->stats_add_max) {
+            fprintf(s->stats_file, "max_avg:%d ", s->average_max);
+            for (j = 0; j < s->nb_components; j++) {
+                c = s->is_rgb ? s->rgba_map[j] : j;
+                fprintf(s->stats_file, "max_%c:%d ", s->comps[j], s->max[c]);
+            }
+        }
+        fprintf(s->stats_file, "\n");
+    }
+
+    return ff_filter_frame(ctx->outputs[0], master);
+}
+
+static av_cold int init(AVFilterContext *ctx)
+{
+    ImgHashContext *s = ctx->priv;
+
+    s->min_mse = +INFINITY;
+    s->max_mse = -INFINITY;
+
+    if (s->stats_file_str) {
+        if (s->stats_version < 2 && s->stats_add_max) {
+            av_log(ctx, AV_LOG_ERROR,
+                "stats_add_max was specified but stats_version < 2.\n" );
+            return AVERROR(EINVAL);
+        }
+        if (!strcmp(s->stats_file_str, "-")) {
+            s->stats_file = stdout;
+        } else {
+            s->stats_file = fopen(s->stats_file_str, "w");
+            if (!s->stats_file) {
+                int err = AVERROR(errno);
+                char buf[128];
+                av_strerror(err, buf, sizeof(buf));
+                av_log(ctx, AV_LOG_ERROR, "Could not open stats file %s: %s\n",
+                       s->stats_file_str, buf);
+                return err;
+            }
+        }
+    }
+
+    if (s->hash_type) {
+        if (!strcmp(s->hash_type, "phash"))
+            s->hash_type_i = PHASH;
+        else if (!strcmp(s->hash_type, "colormoment")) {
+            s->hash_type_i = COLORMOMENT;
+        } else if (!strcmp(s->hash_type, "average"))
+            s->hash_type_i = AVERAGE;
+        else if (!strcmp(s->hash_type, "marrhildreth"))
+            s->hash_type_i = MARRHILDRETH;
+        else if (!strcmp(s->hash_type, "radialvariance"))
+            s->hash_type_i = RADIALVARIANCE;
+        else if (!strcmp(s->hash_type, "blockmean1"))
+            s->hash_type_i = BLOCKMEAN1;
+        else if (!strcmp(s->hash_type, "blockmean2"))
+            s->hash_type_i = BLOCKMEAN2;
+        else {
+            av_log(s, AV_LOG_ERROR, "Bad hash_type given %s\n", s->hash_type);
+            return AVERROR(ENOMEM);
+        }
+    }
+
+    s->fs.on_event = do_psnr;
+    return 0;
+}
+
+static int query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_GRAY8, AV_PIX_FMT_GRAY9, AV_PIX_FMT_GRAY10, AV_PIX_FMT_GRAY12, AV_PIX_FMT_GRAY14, AV_PIX_FMT_GRAY16,
+#define PF_NOALPHA(suf) AV_PIX_FMT_YUV420##suf,  AV_PIX_FMT_YUV422##suf,  AV_PIX_FMT_YUV444##suf
+#define PF_ALPHA(suf)   AV_PIX_FMT_YUVA420##suf, AV_PIX_FMT_YUVA422##suf, AV_PIX_FMT_YUVA444##suf
+#define PF(suf)         PF_NOALPHA(suf), PF_ALPHA(suf)
+        PF(P), PF(P9), PF(P10), PF_NOALPHA(P12), PF_NOALPHA(P14), PF(P16),
+        AV_PIX_FMT_YUV440P, AV_PIX_FMT_YUV411P, AV_PIX_FMT_YUV410P,
+        AV_PIX_FMT_YUVJ411P, AV_PIX_FMT_YUVJ420P, AV_PIX_FMT_YUVJ422P,
+        AV_PIX_FMT_YUVJ440P, AV_PIX_FMT_YUVJ444P,
+        AV_PIX_FMT_GBRP, AV_PIX_FMT_GBRP9, AV_PIX_FMT_GBRP10,
+        AV_PIX_FMT_GBRP12, AV_PIX_FMT_GBRP14, AV_PIX_FMT_GBRP16,
+        AV_PIX_FMT_GBRAP, AV_PIX_FMT_GBRAP10, AV_PIX_FMT_GBRAP12, AV_PIX_FMT_GBRAP16,
+        AV_PIX_FMT_NONE
+    };
+
+    AVFilterFormats *fmts_list = ff_make_format_list(pix_fmts);
+    if (!fmts_list)
+        return AVERROR(ENOMEM);
+    return ff_set_common_formats(ctx, fmts_list);
+}
+
+static int config_input_ref(AVFilterLink *inlink)
+{
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);
+    AVFilterContext *ctx  = inlink->dst;
+    ImgHashContext *s = ctx->priv;
+    double average_max;
+    unsigned sum;
+    int j;
+
+    s->nb_components = desc->nb_components;
+    if (ctx->inputs[0]->w != ctx->inputs[1]->w ||
+        ctx->inputs[0]->h != ctx->inputs[1]->h) {
+        av_log(ctx, AV_LOG_ERROR, "Width and height of input videos must be same.\n");
+        return AVERROR(EINVAL);
+    }
+    if (ctx->inputs[0]->format != ctx->inputs[1]->format) {
+        av_log(ctx, AV_LOG_ERROR, "Inputs must be of same pixel format.\n");
+        return AVERROR(EINVAL);
+    }
+
+    s->max[0] = (1 << desc->comp[0].depth) - 1;
+    s->max[1] = (1 << desc->comp[1].depth) - 1;
+    s->max[2] = (1 << desc->comp[2].depth) - 1;
+    s->max[3] = (1 << desc->comp[3].depth) - 1;
+
+    s->is_rgb = ff_fill_rgba_map(s->rgba_map, inlink->format) >= 0;
+    s->comps[0] = s->is_rgb ? 'r' : 'y' ;
+    s->comps[1] = s->is_rgb ? 'g' : 'u' ;
+    s->comps[2] = s->is_rgb ? 'b' : 'v' ;
+    s->comps[3] = 'a';
+
+    s->planeheight[1] = s->planeheight[2] = AV_CEIL_RSHIFT(inlink->h, desc->log2_chroma_h);
+    s->planeheight[0] = s->planeheight[3] = inlink->h;
+    s->planewidth[1]  = s->planewidth[2]  = AV_CEIL_RSHIFT(inlink->w, desc->log2_chroma_w);
+    s->planewidth[0]  = s->planewidth[3]  = inlink->w;
+    sum = 0;
+    for (j = 0; j < s->nb_components; j++)
+        sum += s->planeheight[j] * s->planewidth[j];
+    average_max = 0;
+    for (j = 0; j < s->nb_components; j++) {
+        s->planeweight[j] = (double) s->planeheight[j] * s->planewidth[j] / sum;
+        average_max += s->max[j] * s->planeweight[j];
+    }
+    s->average_max = lrint(average_max);
+
+    s->dsp.sse_line = desc->comp[0].depth > 8 ? sse_line_16bit : sse_line_8bit;
+    if (ARCH_X86)
+        ff_psnr_init_x86(&s->dsp, desc->comp[0].depth);
+
+    return 0;
+}
+
+static int config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    ImgHashContext *s = ctx->priv;
+    AVFilterLink *mainlink = ctx->inputs[0];
+    int ret;
+
+    ret = ff_framesync_init_dualinput(&s->fs, ctx);
+    if (ret < 0)
+        return ret;
+    outlink->w = mainlink->w;
+    outlink->h = mainlink->h;
+    outlink->time_base = mainlink->time_base;
+    outlink->sample_aspect_ratio = mainlink->sample_aspect_ratio;
+    outlink->frame_rate = mainlink->frame_rate;
+    if ((ret = ff_framesync_configure(&s->fs)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int activate(AVFilterContext *ctx)
+{
+    ImgHashContext *s = ctx->priv;
+    return ff_framesync_activate(&s->fs);
+}
+
+static av_cold void uninit(AVFilterContext *ctx)
+{
+    ImgHashContext *s = ctx->priv;
+
+    if (s->nb_frames > 0) {
+        int j;
+        char buf[256];
+
+        buf[0] = 0;
+        for (j = 0; j < s->nb_components; j++) {
+            int c = s->is_rgb ? s->rgba_map[j] : j;
+            av_strlcatf(buf, sizeof(buf), " %c:%f", s->comps[j],
+                        get_psnr(s->mse_comp[c], s->nb_frames, s->max[c]));
+        }
+        av_log(ctx, AV_LOG_INFO, "PHQM average:%f PSNR%s average:%f min:%f max:%f\n",
+               s->hd / s->nb_frames,
+               buf,
+               get_psnr(s->mse, s->nb_frames, s->average_max),
+               get_psnr(s->max_mse, 1, s->average_max),
+               get_psnr(s->min_mse, 1, s->average_max));
+    }
+
+    ff_framesync_uninit(&s->fs);
+
+    if (s->stats_file && s->stats_file != stdout)
+        fclose(s->stats_file);
+}
+
+static const AVFilterPad img_hash_inputs[] = {
+    {
+        .name         = "main",
+        .type         = AVMEDIA_TYPE_VIDEO,
+    },{
+        .name         = "reference",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_input_ref,
+    },
+    { NULL }
+};
+
+static const AVFilterPad img_hash_outputs[] = {
+    {
+        .name          = "default",
+        .type          = AVMEDIA_TYPE_VIDEO,
+        .config_props  = config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_img_hash= {
+    .name          = "img_hash",
+    .description   = NULL_IF_CONFIG_SMALL("PHQM: Calculate the Perceptual Hash Hamming Difference between two video streams."),
+    .preinit       = img_hash_framesync_preinit,
+    .init          = init,
+    .uninit        = uninit,
+    .query_formats = query_formats,
+    .activate      = activate,
+    .priv_size     = sizeof(ImgHashContext),
+    .priv_class    = &img_hash_class,
+    .inputs        = img_hash_inputs,
+    .outputs       = img_hash_outputs,
+};
diff --git a/libavfilter/vf_perceptual.c b/libavfilter/vf_perceptual.c
new file mode 100644
index 0000000..7bf8037
--- /dev/null
+++ b/libavfilter/vf_perceptual.c
@@ -0,0 +1,160 @@
+/*
+ * PERCEPTUAL FILTER: Chris Kennedy (C) 2019
+ *
+ * Perceptual scoring frame matching
+ *
+ * Tags decoded frames with a perceptual score for the x264
+ * encoder to use.
+ *
+ * License: Apache 2.0
+ *
+ */
+
+/**
+ * @file
+ * perceptual: Perceptual Scoring
+ */
+
+#include "libavutil/adler32.h"
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/file.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/timestamp.h"
+#include "libavfilter/lswsutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+#include "img_hash.h"
+
+typedef struct {
+    const AVClass *class;
+    char *hash_type;
+    double score_multiplier;
+    double score_factor;
+    int hash_type_i;
+    uint64_t frame_count; // frame counter/number
+    AVFrame *lastframe;
+
+    void *priv; // private structure for filter, std FFmpeg API
+} PerceptualContext;
+
+// decides color space raw frame format used via standard LibAV API
+static int query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_YUV420P, AV_PIX_FMT_BGR24, AV_PIX_FMT_GRAY8, AV_PIX_FMT_NONE
+    };
+    return ff_set_common_formats(ctx, ff_make_format_list(pix_fmts));
+}
+
+static av_cold int init(AVFilterContext *ctx)
+{
+    PerceptualContext *perceptual = ctx->priv;
+
+    if (!(perceptual->priv = av_mallocz(sizeof(PerceptualContext))))
+        return AVERROR(ENOMEM);
+
+    if (perceptual->hash_type) {
+        if (!strcmp(perceptual->hash_type, "phash"))
+            perceptual->hash_type_i = PHASH;
+        else if (!strcmp(perceptual->hash_type, "colormoment")) {
+            perceptual->hash_type_i = COLORMOMENT;
+            perceptual->score_multiplier = 1.0;
+        } else if (!strcmp(perceptual->hash_type, "average"))
+            perceptual->hash_type_i = AVERAGE;
+        else if (!strcmp(perceptual->hash_type, "marrhildreth"))
+            perceptual->hash_type_i = MARRHILDRETH;
+        else if (!strcmp(perceptual->hash_type, "radialvariance"))
+            perceptual->hash_type_i = RADIALVARIANCE;
+        else if (!strcmp(perceptual->hash_type, "blockmean1"))
+            perceptual->hash_type_i = BLOCKMEAN1;
+        else if (!strcmp(perceptual->hash_type, "blockmean2"))
+            perceptual->hash_type_i = BLOCKMEAN2;
+        else {
+            av_log(perceptual, AV_LOG_ERROR, "Bad hash_type given %s\n", perceptual->hash_type);
+            return AVERROR(ENOMEM);
+        }
+    }
+    return 0;
+}
+
+static av_cold void uninit(AVFilterContext *ctx)
+{
+    PerceptualContext *perceptual = ctx->priv;
+
+    av_free(perceptual->priv);
+}
+
+static int filter_frame(AVFilterLink *inlink, AVFrame *in)
+{
+    AVFilterContext *ctx = inlink->dst;
+    AVFilterLink *outlink= inlink->dst->outputs[0];
+    PerceptualContext *perceptual = ctx->priv;
+    double score = 0;
+
+    perceptual->frame_count++;
+
+    /* compare last frame with this current frame */
+    if (perceptual->frame_count > 1) {
+        score = getScore(perceptual->lastframe, in, inlink->format, perceptual->hash_type_i);
+        av_log(perceptual, AV_LOG_DEBUG, "Perceptual: %s hamming score %0.1lf\n", perceptual->hash_type, score);
+
+        /* mark frame, normalize to percentage */
+        in->perceptual_score = .01 * FFMIN((score * perceptual->score_multiplier), 100);
+        in->perceptual_score_factor = perceptual->score_factor;
+
+        av_frame_free(&perceptual->lastframe);
+    }
+    /* save last frame */
+    perceptual->lastframe = av_frame_clone(in);
+
+    av_log(perceptual, AV_LOG_DEBUG, "Perceptual: %%%0.1lf frame change\n", in->perceptual_score * 100);
+
+    return ff_filter_frame(outlink, in);
+}
+
+#define OFFSET(x) offsetof(PerceptualContext, x)
+#define FLAGS AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM
+static const AVOption perceptual_options[] = {
+    { "hash_type", "options: phash, colormomenthash, average", OFFSET(hash_type), AV_OPT_TYPE_STRING, {.str = "phash"}, .flags = FLAGS },
+    { "score_multiplier", "multiply the hamming score result by this value. 2.0 by default", OFFSET(score_multiplier),
+        AV_OPT_TYPE_DOUBLE, {.dbl = 2.0}, 0, 100, .flags = FLAGS },
+    { "score_factor", "factor to decrease compression, multiplier for bitrate, range for crf. 2.0 default", OFFSET(score_factor),
+        AV_OPT_TYPE_DOUBLE, {.dbl = 2.0}, 0, 1000, .flags = FLAGS },
+    { NULL }
+};
+
+AVFILTER_DEFINE_CLASS(perceptual);
+
+static const AVFilterPad avfilter_vf_perceptual_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad avfilter_vf_perceptual_outputs[] = {
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_perceptual = {
+    .name          = "perceptual",
+    .description   = NULL_IF_CONFIG_SMALL("Perceptual Scoring Filter"),
+    .priv_size     = sizeof(PerceptualContext),
+    .priv_class    = &perceptual_class,
+    .query_formats = query_formats,
+    .init          = init,
+    .uninit        = uninit,
+    .inputs        = avfilter_vf_perceptual_inputs,
+    .outputs       = avfilter_vf_perceptual_outputs,
+};
diff --git a/libavutil/frame.c b/libavutil/frame.c
index dcf1fc3..94e7644 100644
--- a/libavutil/frame.c
+++ b/libavutil/frame.c
@@ -163,6 +163,8 @@ FF_ENABLE_DEPRECATION_WARNINGS
     frame->color_range         = AVCOL_RANGE_UNSPECIFIED;
     frame->chroma_location     = AVCHROMA_LOC_UNSPECIFIED;
     frame->flags               = 0;
+    frame->perceptual_score    = -1;
+    frame->perceptual_score_factor    = 2.0;
 }
 
 static void free_side_data(AVFrameSideData **ptr_sd)
@@ -373,6 +375,8 @@ FF_ENABLE_DEPRECATION_WARNINGS
     dst->colorspace             = src->colorspace;
     dst->color_range            = src->color_range;
     dst->chroma_location        = src->chroma_location;
+    dst->perceptual_score       = src->perceptual_score;
+    dst->perceptual_score_factor       = src->perceptual_score_factor;
 
     av_dict_copy(&dst->metadata, src->metadata, 0);
 
@@ -453,6 +457,8 @@ int av_frame_ref(AVFrame *dst, const AVFrame *src)
     dst->channels       = src->channels;
     dst->channel_layout = src->channel_layout;
     dst->nb_samples     = src->nb_samples;
+    dst->perceptual_score = src->perceptual_score;
+    dst->perceptual_score_factor = src->perceptual_score_factor;
 
     ret = frame_copy_props(dst, src, 0);
     if (ret < 0)
diff --git a/libavutil/frame.h b/libavutil/frame.h
index 5d3231e..c9df011 100644
--- a/libavutil/frame.h
+++ b/libavutil/frame.h
@@ -672,6 +672,13 @@ typedef struct AVFrame {
      * for the target frame's private_ref field.
      */
     AVBufferRef *private_ref;
+
+    /**
+     * perceptual score
+     * 0.00 - 1.00 percentage of perceptual match to the previous frame
+     */
+    float perceptual_score;
+    float perceptual_score_factor;
 } AVFrame;
 
 #if FF_API_FRAME_GET_SET
